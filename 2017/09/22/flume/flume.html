<hr>
<p>title: Flume（基础概念&amp;配置）<br>date: 2017-09-22 4:42<br>tags: flume<br>categories: elk</p>
<hr>
<h3 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h3><p>Flume NG是Cloudera提供的一个分布式、可靠、可用的系统，它能够将不同数据源的海量日志数据进行高效收集、聚合、移动，最后存储到一个中心化数据存储系统中。由原来的Flume OG到现在的Flume NG，进行了架构重构，并且现在NG版本完全不兼容原来的OG版本。经过架构重构后，Flume NG更像是一个轻量的小工具，非常简单，容易适应各种方式日志收集，并支持failover和负载均衡。</p>
<ul>
<li>Flume 使用 java 编写，其需要运行在 Java1.7 或更高版本之上。</li>
</ul>
<p>官方网站：<a href="http://flume.apache.org/">http://flume.apache.org/</a><br>用户文档：<a href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a><br>开发文档：<a href="http://flume.apache.org/FlumeDeveloperGuide.html">http://flume.apache.org/FlumeDeveloperGuide.html</a></p>
<h3 id="2、安装"><a href="#2、安装" class="headerlink" title="2、安装"></a>2、安装</h3><p>配置文件路径</p>
<h3 id="3、关键词"><a href="#3、关键词" class="headerlink" title="3、关键词"></a>3、关键词</h3><p><strong>Flume的架构主要有一下几个核心概念：</strong><br>Event：数据流最小单元，带有一个可选的消息头header<br>Flow：Event从源点到达目的点的迁移的抽象<br>Client：操作位于源点处的Event，将其发送到Flume Agent<br>Agent：一个独立的Flume进程，包含组件Source、Channel、Sink<br>Source：用来消费传递到该组件的Event<br>Channel：中转Event的一个临时存储，保存有Source组件传递过来的Event<br>Sink：从Channel中读取并移除Event，将Event传递到Flow Pipeline中的下一个Agent（如果有的话）</p>
<h3 id="4、数据流"><a href="#4、数据流" class="headerlink" title="4、数据流"></a>4、数据流</h3><p>1、Flume 的核心是把数据从数据源收集过来，再送到目的地。为了保证输送一定成功，在送到目的地之前，会先缓存数据，待数据真正到达目的地后，删除自己缓存的数据。</p>
<p>2、Flume 传输的数据的基本单位是 Event，如果是文本文件，通常是一行记录，这也是事务的基本单位。Event 从 Source，流向 Channel，再到 Sink，本身为一个 byte 数组，并可携带 headers 信息。Event 代表着一个数据流的最小完整单元，从外部数据源来，向外部的目的地去。</p>
<p>3、Flume 运行的核心是 Agent。它是一个完整的数据收集工具，含有三个核心组件，分别是 source、channel、sink。通过这些组件，Event 可以从一个地方流向另一个地方，如下图所示。</p>
<p>{% asset_img 1.png %}</p>
<p>由图易得，flume有三个部分<br>source–&gt;channel–&gt;sink<br>（以为source怎么确保channel已经缓存，channel怎么确保sink已经消费（tcp看多了））</p>
<p>1、source 可以接收外部源发送过来的数据。不同的 source，可以接受不同的数据格式。比如有目录池(spooling directory)数据源，可以监控指定文件夹中的新文件变化，如果目录中有文件产生，就会立刻读取其内容。<br>2、channel 是一个存储地，接收 source 的输出，直到有 sink 消费掉 channel 中的数据。channel 中的数据直到进入到下一个channel中或者进入终端才会被删除。当 sink 写入失败后，可以自动重启，不会造成数据丢失，因此很可靠。<br>3、sink 会消费 channel 中的数据，然后送给外部源或者其他 source。如数据可以写入到 HDFS 或者 HBase 中。</p>
<h3 id="5、核心组件"><a href="#5、核心组件" class="headerlink" title="5、核心组件"></a>5、核心组件</h3><h4 id="5-1、source"><a href="#5-1、source" class="headerlink" title="5.1、source:"></a>5.1、source:</h4><h5 id="5-1-1-source介绍"><a href="#5-1-1-source介绍" class="headerlink" title="5.1.1 source介绍"></a>5.1.1 source介绍</h5><p>Client端操作消费数据的来源，Flume 支持 Avro，log4j，syslog 和 http post(body为json格式)。可以让应用程序同已有的Source直接打交道，如AvroSource，SyslogTcpSource。也可以 写一个 Source，以 IPC 或 RPC 的方式接入自己的应用，Avro和 Thrift 都可以(分别有 NettyAvroRpcClient 和 ThriftRpcClient 实现了 RpcClient接口)，其中 Avro 是默认的 RPC 协议。具体代码级别的 Client 端数据接入，可以参考官方手册。</p>
<p>对现有程序改动最小的使用方式是使用是直接读取程序原来记录的日志文件，基本可以实现无缝接入，不需要对现有程序进行任何改动。 对于直接读取文件 Source,有两种方式：</p>
<ul>
<li><p>ExecSource: 以运行 Linux 命令的方式，持续的输出最新的数据，如 tail -F 文件名 指令，在这种方式下，取的文件名必须是指定的。 ExecSource 可以实现对日志的实时收集，但是存在Flume不运行或者指令执行出错时，将无法收集到日志数据，无法保证日志数据的完整性。</p>
</li>
<li><p>SpoolSource: 监测配置的目录下新增的文件，并将文件中的数据读取出来。需要注意两点：拷贝到 spool 目录下的文件不可以再打开编辑；spool 目录下不可包含相应的子目录。</p>
</li>
</ul>
<blockquote>
<p>1 SpoolSource 虽然无法实现实时的收集数据，但是可以使用以分钟的方式分割文件，趋近于实时。<br>2 如果应用无法实现以分钟切割日志文件的话， 可以两种收集方式结合使用。 在实际使用的过程中，可以结合 log4j 使用，使用 log4j的时候，将 log4j 的文件分割机制设为1分钟一次，将文件拷贝到spool的监控目录。<br>3 log4j 有一个 TimeRolling 的插件，可以把 log4j 分割文件到 spool 目录。基本实现了实时的监控。Flume 在传完文件之后，将会修改文件的后缀，变为 .COMPLETED（后缀也可以在配置文件中灵活指定）。</p>
</blockquote>
<h5 id="5-1-2-source配置行："><a href="#5-1-2-source配置行：" class="headerlink" title="5.1.2 source配置行："></a>5.1.2 source配置行：</h5><pre><code>1、exec
agent.sources.s1.type=exec
agent.sources.s1.command=tail -F /Users/it-od-m/Downloads/abc.log

2、spolldir
agent.sources.s1.type = spooldir  
agent.sources.s1.spoolDir = /Users/it-od-m/logs  
agent.sources.s1.fileHeader = true
</code></pre><h5 id="5-1-3-source的其他输入类型"><a href="#5-1-3-source的其他输入类型" class="headerlink" title="5.1.3 source的其他输入类型"></a>5.1.3 source的其他输入类型</h5><ul>
<li>主要使用Exec Source和Spooling Directory Source</li>
</ul>
<table>
<thead>
<tr>
<th>Source类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Exec Source</td>
<td>基于Unix的command在标准输出上生产数据</td>
</tr>
<tr>
<td>Spooling Directory Source</td>
<td>监控指定目录内数据变更</td>
</tr>
<tr>
<td>Avro Source</td>
<td>支持Avro协议（实际上是Avro RPC），内置支持     </td>
</tr>
<tr>
<td>Thrift Source</td>
<td>支持Thrift协议，内置支持     </td>
</tr>
<tr>
<td>JMS Source</td>
<td>从JMS系统（消息、主题）中读取数据，ActiveMQ已经测试过          </td>
</tr>
<tr>
<td>Twitter 1% firehose Source</td>
<td>通过API持续下载Twitter数据，试验性质     </td>
</tr>
<tr>
<td>Netcat Source</td>
<td>监控某个端口，将流经端口的每一个文本行数据作为Event输入     </td>
</tr>
<tr>
<td>Sequence Generator Source</td>
<td>序列生成器数据源，生产序列数据     </td>
</tr>
<tr>
<td>Syslog Sources</td>
<td>读取syslog数据，产生Event，支持UDP和TCP两种协议     </td>
</tr>
<tr>
<td>HTTP Source</td>
<td>基于HTTP POST或GET方式的数据源，支持JSON、BLOB表示形式     </td>
</tr>
<tr>
<td>Legacy Sources</td>
<td>兼容老的Flume OG中Source（0.9.x版本）</td>
</tr>
</tbody>
</table>
<h4 id="5-2、-Channel"><a href="#5-2、-Channel" class="headerlink" title="5.2、 Channel"></a>5.2、 Channel</h4><h5 id="5-2-1-channel介绍"><a href="#5-2-1-channel介绍" class="headerlink" title="5.2.1 channel介绍"></a>5.2.1 channel介绍</h5><p>channel目前有集中模式，分别是 Memory Channel, JDBC Channel , File Channel，Psuedo Transaction Channel。比较常见的是前三种 channel。</p>
<ul>
<li>MemoryChannel 可以实现高速的吞吐，但是无法保证数据的完整性。</li>
<li>MemoryRecoverChannel 在官方文档的建议上已经建义使用FileChannel来替换。</li>
<li>FileChannel保证数据的完整性与一致性。在具体配置FileChannel时，建议FileChannel设置的目录和程序日志文件保存的目录设成不同的磁盘，以便提高效率。</li>
</ul>
<blockquote>
<p>File Channel 是一个持久化的隧道（channel），它持久化所有的事件，并将其存储到磁盘中。因此，即使 Java 虚拟机当掉，或者操作系统崩溃或重启，再或者事件没有在管道中成功地传递到下一个代理（agent），这一切都不会造成数据丢失。Memory Channel 是一个不稳定的隧道，其原因是由于它在内存中存储所有事件。如果 java 进程死掉，任何存储在内存的事件将会丢失。另外，内存的空间收到 RAM大小的限制,而 File Channel 这方面是它的优势，只要磁盘空间足够，它就可以将所有事件数据存储到磁盘上。</p>
</blockquote>
<h5 id="5-2-2-Flume-Channel-支持的类型："><a href="#5-2-2-Flume-Channel-支持的类型：" class="headerlink" title="5.2.2 Flume Channel 支持的类型："></a>5.2.2 Flume Channel 支持的类型：</h5><table>
<thead>
<tr>
<th>Channel类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Memory Channel</td>
<td>Event数据存储在内存中</td>
</tr>
<tr>
<td>JDBC Channel</td>
<td>Event数据存储在持久化存储中，当前Flume Channel内置支持Derby</td>
</tr>
<tr>
<td>File Channel</td>
<td>Event数据存储在磁盘文件中</td>
</tr>
<tr>
<td>Spillable Memory Channel</td>
<td>Event数据存储在内存中和磁盘上，当内存队列满了，会持久化到磁盘文件（当前试验性的，不建议生产环境使用）</td>
</tr>
<tr>
<td>Pseudo Transaction Channel</td>
<td>测试用途</td>
</tr>
<tr>
<td>Custom Channel</td>
<td>自定义Channel实现</td>
</tr>
</tbody>
</table>
<h5 id="5-2-3-channel配置段"><a href="#5-2-3-channel配置段" class="headerlink" title="5.2.3 channel配置段"></a>5.2.3 channel配置段</h5><pre><code>#设置Kafka接收器
agent.sinks.k1.type= org.apache.flume.sink.kafka.KafkaSink
#设置Kafka的broker地址和端口号
agent.sinks.k1.brokerList=127.0.0.1:9092
#设置Kafka的Topic
agent.sinks.k1.topic=testKJ1
#设置序列化方式
agent.sinks.k1.serializer.class=kafka.serializer.StringEncoder
agent.sinks.k1.channel=c1
</code></pre><h4 id="5-3、-sink"><a href="#5-3、-sink" class="headerlink" title="5.3、 sink"></a>5.3、 sink</h4><h5 id="5-3-1-sink介绍"><a href="#5-3-1-sink介绍" class="headerlink" title="5.3.1 sink介绍"></a>5.3.1 sink介绍</h5><p>Sink在设置存储数据时，可以向文件系统、数据库、hadoop存数据，在日志数据较少时，可以将数据存储在文件系中，并且设定一定的时间间隔保存数据。在日志数据较多时，可以将相应的日志数据存储到Hadoop中，便于日后进行相应的数据分析。</p>
<h5 id="5-3-2-Flume-Sink支持的类型（居然没有kafka）"><a href="#5-3-2-Flume-Sink支持的类型（居然没有kafka）" class="headerlink" title="5.3.2 Flume Sink支持的类型（居然没有kafka）"></a>5.3.2 Flume Sink支持的类型（居然没有kafka）</h5><table>
<thead>
<tr>
<th>Sink类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>HDFS Sink</td>
<td>数据写入HDFS</td>
</tr>
<tr>
<td>Logger Sink</td>
<td>数据写入日志文件</td>
</tr>
<tr>
<td>Avro Sink</td>
<td>数据被转换成Avro Event，然后发送到配置的RPC端口上</td>
</tr>
<tr>
<td>Thrift Sink</td>
<td>数据被转换成Thrift Event，然后发送到配置的RPC端口上</td>
</tr>
<tr>
<td>IRC Sink</td>
<td>数据在IRC上进行回放</td>
</tr>
<tr>
<td>File Roll Sink</td>
<td>存储数据到本地文件系统</td>
</tr>
<tr>
<td>Null Sink</td>
<td>丢弃到所有数据</td>
</tr>
<tr>
<td>HBase Sink</td>
<td>数据写入HBase数据库</td>
</tr>
<tr>
<td>Morphline Solr Sink</td>
<td>数据发送到Solr搜索服务器（集群）</td>
</tr>
<tr>
<td>ElasticSearch Sink</td>
<td>数据发送到Elastic Search搜索服务器（集群）</td>
</tr>
<tr>
<td>Kite Dataset Sink</td>
<td>写数据到Kite Dataset，试验性质的</td>
</tr>
<tr>
<td>Custom Sink</td>
<td>自定义Sink实现</td>
</tr>
</tbody>
</table>
<h5 id="5-3-3配置段"><a href="#5-3-3配置段" class="headerlink" title="5.3.3配置段"></a>5.3.3配置段</h5><pre><code>#设置Kafka接收器
agent.sinks.k1.type= org.apache.flume.sink.kafka.KafkaSink
#设置Kafka的broker地址和端口号
agent.sinks.k1.brokerList=127.0.0.1:9092
#设置Kafka的Topic
agent.sinks.k1.topic=testKJ1
#设置序列化方式
agent.sinks.k1.serializer.class=kafka.serializer.StringEncoder

agent.sinks.k1.channel=c1
</code></pre><h4 id="5-4-可靠性-三者的关系"><a href="#5-4-可靠性-三者的关系" class="headerlink" title="5.4 可靠性 三者的关系"></a>5.4 可靠性 三者的关系</h4><p>Flume 的核心是把数据从数据源收集过来，再送到目的地。为了保证输送一定成功，在送到目的地之前，会先缓存数据，待数据真正到达目的地后，删除自己缓存的数据。</p>
<p>Flume 使用事务性的方式保证传送Event整个过程的可靠性。Sink 必须在 Event 被存入 Channel 后，或者，已经被传达到下一站agent里，又或者，已经被存入外部数据目的地之后，才能把 Event 从 Channel 中 remove 掉。这样数据流里的 event 无论是在一个 agent 里还是多个 agent 之间流转，都能保证可靠，因为以上的事务保证了 event 会被成功存储起来。</p>
<p>Channel 的多种实现在可恢复性上有不同的保证。也保证了 event 不同程度的可靠性。比如 Flume 支持在本地保存一份文件 channel 作为备份，而memory channel 将 event 存在内存 queue 里，速度快，但丢失的话无法恢复。</p>
<p>###6 使用情景（工作模式）</p>
<ul>
<li>多个 agent 顺序连接：</li>
<li><p>#图<br>可以将多个Agent顺序连接起来，将最初的数据源经过收集，存储到最终的存储系统中。这是最简单的情况，一般情况下，应该控制这种顺序连接的Agent的数量，因为数据流经的路径变长了，如果不考虑failover的话，出现故障将影响整个Flow上的Agent收集服务。</p>
</li>
<li><p>多个Agent的数据汇聚到同一个Agent:</p>
</li>
<li><p>#图<br>这种情况应用的场景比较多，比如要收集Web网站的用户行为日志，Web网站为了可用性使用的负载均衡的集群模式，每个节点都产生用户行为日志，可以为每个节点都配置一个Agent来单独收集日志数据，然后多个Agent将数据最终汇聚到一个用来存储数据存储系统，如HDFS上。</p>
</li>
<li><p>多路（Multiplexing）Agent</p>
</li>
<li>#图<br>这种模式，有两种方式，一种是用来复制（Replication），另一种是用来分流（Multiplexing）。Replication方式，可以将最前端的数据源复制多份，分别传递到多个channel中，每个channel接收到的数据都是相同的。</li>
</ul>
<h3 id="7、配置文件"><a href="#7、配置文件" class="headerlink" title="7、配置文件"></a>7、配置文件</h3><pre><code>＃example.conf：单节点Flume配置

＃命名此代理的组件
a1.sources  =  r1 #指定a1为代理，源r1
a1.sinks  =  k1 #指定
a1.channels  =  c1 

＃描述/配置源
a1.sources.r1.type  =  netcat 
a1。 sources.r1.bind  =  localhost 
a1.sources.r1.port  =  44444 

＃描述sink 
a1.sinks.k1.type  =  logger 

＃使用在内存中缓存事件的通道
a1.channels.c1.type  =  memory 
a1.channels .c1.capacity  =  1000 
a1.channels.c1.transactionCapacity  = 100 

＃将源和接收器绑定到通道
a1.sources.r1.channels  =  c1 
a1.sinks.k1.channel  =  c1
</code></pre><p>启动flume</p>
<pre><code>$ bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console
</code></pre><p>常用配置模式一</p>
<pre><code>agent.sources.s1.type=exec
agent.sources.s1.command=tail -F /Users/it-od-m/Downloads/abc.log
agent.sources.s1.channels=c1
agent.channels.c1.type=memory
agent.channels.c1.capacity=10000
agent.channels.c1.transactionCapacity=100

#设置Kafka接收器
agent.sinks.k1.type= org.apache.flume.sink.kafka.KafkaSink
#设置Kafka的broker地址和端口号
agent.sinks.k1.brokerList=127.0.0.1:9092
#设置Kafka的Topic
agent.sinks.k1.topic=testKJ1
#设置序列化方式
agent.sinks.k1.serializer.class=kafka.serializer.StringEncoder

agent.sinks.k1.channel=c1
</code></pre><p>常用配置模式二</p>
<pre><code>Agent名称定义为agent.   
Source:可以理解为输入端，定义名称为s1  
channel：传输频道，定义为c1，设置为内存模式  
sinks：可以理解为输出端，定义为sk1,  

agent.sources = s1    
agent.channels = c1  
agent.sinks = sk1  

#设置Source的内省为netcat 端口为5678，使用的channel为c1  
agent.sources.s1.type = netcat  
agent.sources.s1.bind = localhost  
agent.sources.s1.port = 3456  
agent.sources.s1.channels = c1  

#设置Sink为logger模式，使用的channel为c1  
agent.sinks.sk1.type = logger  
agent.sinks.sk1.channel = c1  
#设置channel信息  
agent.channels.c1.type = memory #内存模式  
agent.channels.c1.capacity = 1000     
agent.channels.c1.transactionCapacity = 100 #传输参数设置。
</code></pre><p>常用配置模式三</p>
<ul>
<li>扫描目录新增文件</li>
</ul>
<pre><code>agent.sources = s1  
agent.channels = c1  
agent.sinks = sk1  

#设置spooldir  
agent.sources.s1.type = spooldir  
agent.sources.s1.spoolDir = /Users/it-od-m/logs  
agent.sources.s1.fileHeader = true  

agent.sources.s1.channels = c1  
agent.sinks.sk1.type = logger  
agent.sinks.sk1.channel = c1  

#In Memory !!!  
agent.channels.c1.type = memory  
agent.channels.c1.capacity = 10004  
agent.channels.c1.transactionCapacity = 100
我们今天重点使用第一种模式，因为要与Kafka相结合。
配置好参数以后，回到如下目录：
</code></pre><p>作者：小程故事多<br>链接：<a href="http://www.jianshu.com/p/f0a08bd4f975">http://www.jianshu.com/p/f0a08bd4f975</a><br>來源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>来源：<a href="http://blog.javachen.com/2014/07/22/flume-ng.html">http://blog.javachen.com/2014/07/22/flume-ng.html</a></p>
<p>###还差工作模式，配置(一般配置和kafka配置)，命名规范，</p>
